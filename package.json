{
  "name": "ai-commit-message",
  "displayName": "Ai Commit Message",
  "description": "VS Code extension which helps to generate AI commit messages using ChatGPT",
  "version": "1.1.7",
  "homepage": "https://github.com/kos-codes/AI_CommitMessage#readme",
  "bugs": "https://github.com/kos-codes/AI_CommitMessage/issues",
  "repository": {
    "type": "git",
    "url": "https://github.com/kos-codes/AI_CommitMessage"
  },
  "license": "MIT",
  "engines": {
    "vscode": "^1.76.0"
  },
  "publisher": "kos-codes",
  "categories": [
    "Other",
    "SCM Providers"
  ],
  "keywords": [
    "Commit",
    "AI",
    "ChatGPT",
    "GPT",
    "git",
    "repository"
  ],
  "icon": "assets/images/icon256.png",
  "activationEvents": [],
  "main": "./out/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "aicommitmessage.generateAICommit",
        "title": "Generate AI commit",
        "icon": {
          "dark": "assets/icons/commit-dark.svg",
          "light": "assets/icons/commit-light.svg"
        }
      },
      {
        "command": "aicommitmessage.setOpenAIApiKey",
        "title": "Set OpenAI API key"
      }
    ],
    "menus": {
      "scm/title": [
        {
          "command": "aicommitmessage.generateAICommit",
          "when": "scmProvider == git",
          "group": "navigation"
        }
      ]
    },
    "configuration": {
      "title": "GPT Commit",
      "properties": {
        "aicommitmessage.appearance.delimeter": {
          "type": "string",
          "default": "",
          "description": "Delimeter between commit lines"
        },
        "aicommitmessage.general.generator": {
          "type": "string",
          "enum": [
            "ChatGPT"
          ],
          "default": "ChatGPT",
          "description": "Generator used to create commit messages"
        },
        "aicommitmessage.general.messageApproveMethod": {
          "type": "string",
          "enum": [
            "Quick pick",
            "Message file"
          ],
          "default": "Quick pick",
          "description": "Method used to approve generated commit messages"
        },
        "aicommitmessage.openAI.apiKey": {
          "type": "string",
          "default": "",
          "description": "Needed for generating AI commit messages"
        },
        "aicommitmessage.openAI.gptVersion": {
          "type": "string",
          "enum": [
            "gpt-4o-2024-05-13",
            "gpt-4o-mini",
            "gpt-4o",
            "gpt-4o-2024-08-06",
            "gpt-4-0125-preview",
            "gpt-3.5-turbo",
            "gpt-4-turbo-preview",
            "gpt-3.5-turbo-0125",
            "gpt-4-1106-preview",
            "gpt-3.5-turbo-1106",
            "gpt-3.5-turbo-16k",
            "gpt-4o-mini-2024-07-18",
            "gpt-3.5-turbo-instruct-0914",
            "gpt-4-0613",
            "gpt-3.5-turbo-instruct",
            "gpt-4-turbo-2024-04-09",
            "gpt-4-turbo",
            "gpt-4",
            "o3-mini",
            "llama-3-sonar-small-32k-chat",
            "llama-3-sonar-small-32k-online",
            "llama-3-sonar-large-32k-chat",
            "llama-3-sonar-large-32k-online",
            "llama-3-8b-instruct",
            "llama-3-70b-instruct",
            "mixtral-8x7b-instruct"
          ],
          "default": "gpt-4o",
          "description": "Version of GPT used by OpenAI or perplexity.ai"
        },
        "aicommitmessage.openAI.customEndpoint": {
          "type": "string",
          "default": "openai",
          "description": "Enter \"openai\" or \"perplexity\" or enter a custom endpoint URL."
        },
        "aicommitmessage.openAI.temperature": {
          "type": "number",
          "default": 0.6,
          "description": "Controls randomness. Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive"
        },
        "aicommitmessage.openAI.maxTokens": {
          "type": "number",
          "default": 196,
          "description": "The maximum number of tokens to generate. Requests can use up to 2048 tokens shared between prompt and completion"
        },
        "aicommitmessage.openAI.language": {
          "type": "string",
          "enum": [
            "English",
            "Korean",
            "Japanese",
            "Chinese",
            "Spanish",
            "Arabic",
            "Portuguese",
            "Russian",
            "French",
            "German",
            "Italian"
          ],
          "default": "English",
          "description": "The language of the prompt. The default language is English (en)."
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run esbuild-base -- --minify",
    "esbuild-base": "esbuild ./src/extension.ts --bundle --outfile=out/extension.js --external:vscode --format=cjs --platform=node",
    "build": "npm run esbuild-base -- --sourcemap",
    "watch": "npm run esbuild-base -- --sourcemap --watch",
    "lint": "eslint src --ext ts",
    "package": "vsce package --no-yarn",
    "package:publish": "vsce publish --no-yarn"
  },
  "devDependencies": {
    "@types/glob": "^8.1.0",
    "@types/node": "16.x",
    "@types/vscode": "^1.76.0",
    "@typescript-eslint/eslint-plugin": "^5.56.0",
    "@typescript-eslint/parser": "^5.56.0",
    "@vscode/test-electron": "^2.3.0",
    "esbuild": "^0.17.14",
    "eslint": "^8.36.0",
    "glob": "^8.1.0",
    "typescript": "^4.9.5"
  },
  "dependencies": {
    "execa": "^9.2.0",
    "openai": "^4.52.0",
    "zod": "^3.23.8"
  }
}